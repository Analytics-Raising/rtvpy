{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Manipulation\n",
    "author: Juma Shafara\n",
    "date: \"10-31-2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp manipulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def set_row_as_header(df:pd.DataFrame=None, row_num:int=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Set the specified row as column names for the given DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if row_num is None or df is None:\n",
    "        raise ValueError(\"df and row_num must be an provided\")\n",
    "    \n",
    "    new_header = df.iloc[row_num]  \n",
    "    df = df[row_num + 1:]  \n",
    "    df.columns = new_header  \n",
    "\n",
    "    # set header as strings\n",
    "    df.columns = df.columns.astype(str)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "def create_dec_dummies(df):\n",
    "    # Find columns that end with '_dec'\n",
    "    dec_columns = [col for col in df.columns if col.endswith('_dec')]\n",
    "    \n",
    "    # Explode each list in the columns, and concatenate all exploded columns together\n",
    "    df_expanded = pd.concat([df[col].explode() for col in dec_columns], axis=1)\n",
    "    \n",
    "    # Create dummies for each unique value in the columns ending with '_dec'\n",
    "    dummies = pd.get_dummies(df_expanded, prefix=dec_columns).groupby(level=0).sum()\n",
    "    \n",
    "    # Concatenate the original DataFrame with the dummies\n",
    "    df = pd.concat([df, dummies], axis=1).drop(columns=dec_columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set specific row as header\n",
    "\n",
    "To set a specific row as header (column names), you can use the `setRowAsHeader` from `manipulate` as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1.0', '6.0', '55.0', '1.0', '0.3265457238059978', '0', '0', '0', '0',\n",
       "       '1', '1', '0', '2.0', '0', '1.0', '1', '0', '97', '0', '0.0', '-99',\n",
       "       '0', '1', 'Struggling'],\n",
       "      dtype='object', name=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rtvpy.manipulate import set_row_as_header\n",
    "\n",
    "dataset = pd.read_csv('2022_data_selected.csv')\n",
    "dataset = set_row_as_header(df=dataset, row_num=0)\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export \n",
    "import pandas as pd\n",
    "\n",
    "def create_region_district_mapping():\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping districts to their respective regions\n",
    "    Including explicit entries for GAC and Standard variants\n",
    "    All district keys are in lowercase for consistent matching\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        # South West Region\n",
    "        'mitooma': 'South_West',\n",
    "        'rubanda': 'South_West',\n",
    "        'kanungu': 'South_West',\n",
    "        'rukungiri': 'South_West',\n",
    "        'rubirizi': 'South_West',\n",
    "        'rukiga': 'South_West',\n",
    "        \n",
    "        # Mid West Region\n",
    "        'kagadi': 'Mid_West',\n",
    "        'kagadi - gac': 'Mid_West',\n",
    "        'kagadi - standard': 'Mid_West',\n",
    "        'kagadi_gac': 'Mid_West',\n",
    "        'kagadi_standard': 'Mid_West',\n",
    "        'kyenjojo': 'Mid_West',\n",
    "        'kyenjojo - gac': 'Mid_West',\n",
    "        'kyenjojo - standard': 'Mid_West',\n",
    "        'kibaale': 'Mid_West',\n",
    "        'kiryandongo': 'Mid_West',\n",
    "        \n",
    "        # Eastern Region\n",
    "        'kaliro': 'Eastern',\n",
    "        'luuka': 'Eastern'\n",
    "    }\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export \n",
    "\n",
    "\n",
    "def standardize_district_names(df, district_col='pre_district'):\n",
    "    \"\"\"\n",
    "    Standardizes district names by converting to lowercase and stripping whitespace\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    district_col (str): Name of the district column\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with standardized district names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[district_col] = df[district_col].str.strip().str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export \n",
    "\n",
    "\n",
    "def populate_region_column(df, district_col='pre_district', region_col='region'):\n",
    "    \"\"\"\n",
    "    Populates the region column in a dataframe based on the district-region mapping\n",
    "    Handles case sensitivity by converting districts to lowercase before mapping\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    district_col (str): Name of the district column\n",
    "    region_col (str): Name of the region column to be populated\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with populated region column\n",
    "    \"\"\"\n",
    "    # First standardize the district names\n",
    "    df = standardize_district_names(df, district_col)\n",
    "    \n",
    "    # Create and apply the mapping\n",
    "    mapping = create_region_district_mapping()\n",
    "    df[region_col] = df[district_col].map(mapping)\n",
    "    \n",
    "    # Print any districts that weren't matched\n",
    "    unmatched = df[df[region_col].isna()][district_col].unique()\n",
    "    if len(unmatched) > 0:\n",
    "        print(f\"Warning: The following districts were not found in the mapping: {unmatched}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def create_dummies_from_list(df, column_name, prefix=None):\n",
    "    \"\"\"\n",
    "    Create dummy variables from a column containing list-like strings,\n",
    "    splitting into individual values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "    column_name : str\n",
    "        Name of the column containing list-like strings\n",
    "    prefix : str, optional\n",
    "        Prefix for the dummy columns\n",
    "    \"\"\"\n",
    "    # Set prefix\n",
    "    if prefix is None:\n",
    "        prefix = column_name.lower()\n",
    "    \n",
    "    # Convert string representation of lists to actual lists and extract unique values\n",
    "    all_values = set()\n",
    "    \n",
    "    def safe_eval_list(x):\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        try:\n",
    "            # Safely evaluate string representation of list\n",
    "            lst = ast.literal_eval(x)\n",
    "            return [str(item).strip() for item in lst]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    # Process each row and collect unique values\n",
    "    for item in df[column_name].dropna():\n",
    "        values = safe_eval_list(item)\n",
    "        all_values.update(values)\n",
    "    \n",
    "    # Create dummy columns\n",
    "    dummies = {}\n",
    "    for value in all_values:\n",
    "        # Clean column name\n",
    "        col_name = f\"{prefix}_{value.lower().replace('/', '_').replace(' ', '_').replace(',', '').replace('(', '').replace(')', '')}\"\n",
    "        \n",
    "        # Create the dummy column\n",
    "        dummies[col_name] = df[column_name].apply(\n",
    "            lambda x: 1 if value in safe_eval_list(x) else 0\n",
    "        )\n",
    "    \n",
    "    return pd.DataFrame(dummies, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
